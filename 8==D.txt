---------------------------------------------------------------------------------------------------------------------
EXP2
create directory in repo .GitHub/workflows/
add file ci-cd-pipeline.yml
       ^
name: CI Pipeline

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '16'

      - name: Install dependencies
        run: npm install

      - name: Run tests
        run: npm test

push the file to repo
enable pages for the master branch
see the result, make change to html and see the result again
-------------------------------------------------------------------------------------------------------------------
EXP4 
docker pull registry.k8s.io/kube-apiserver:v1.32.2
docker pull registry.k8s.io/pause:3.9
docker pull registry.k8s.io/coredns/coredns:v1.11.1
docker pull registry.k8s.io/kube-controller-manager:v1.32.2
docker pull registry.k8s.io/kube-scheduler:v1.32.2
docker pull registry.k8s.io/kube-proxy:v1.32.2
docker pull registry.k8s.io/etcd:3.5.15-0

$version = Invoke-RestMethod -Uri "https://dl.k8s.io/release/stable.txt"
Invoke-WebRequest -Uri "https://dl.k8s.io/release/$version/bin/windows/amd64/kubectl.exe" -OutFile "$env:USERPROFILE\Downloads\kubectl.exe"
Move-Item "$env:USERPROFILE\Downloads\kubectl.exe" "C:\Windows\System32\kubectl.exe"

kubectl version –client
docker login

kubectl cluster-info
kubectl get nodes
kubectl create deployment my-nginx --image=nginx
kubectl get deployments
kubectl get pods
kubectl expose deployment my-nginx --type=NodePort --port=80
kubectl get svc

kubectl create deployment my-apache --image=httpd
kubectl expose deployment my-apache --type=NodePort --port=80
kubectl get svc my-apache

kubectl get all
kubectl delete svc my-nginx
kubectl delete deployment my-nginx
kubectl delete svc my-apache
kubectl delete deployment my-apache
kubectl get all
------------------------------------------------------------------------------------------------------
EXP5

variable "MV1" {
type = string
default = "HELLO WORLD!!"
} ==> as .tf

terraform console
var.MV1
------------------------------------------------------------------------------------------------------
EXP6
user on aws, access keys, Linux instance EC2

provider "aws" {
access_key = < > 
secret_key = < >
region = "ap-south-1"
}
resource "aws_instance" "terraformUser" {
ami = <region specific ami"
instance_type = "t3.micro"
count = 3
tags = { Name = "Smeet" }
} ==> as .tf

terraform init 
terraform plan 
terraform apply
terraform destroy
------------------------------------------------------------------------------------------------------
EXP7A

terraform {
required_providers {
docker = {
source = "kreuzwerker/docker"
version = "2.14.0"
} } }
provider "docker" {
host = "npipe:///.//pipe//docker_engine"
}
resource "docker_image" "redis" {
name = "redis:latest" 
} ==> as docker.tf

terraform init, plan, apply, destroy
------------------------------------------------------------------------------------------------------
EXP7B

terraform {
  required_providers {
    docker = {
      source  = "kreuzwerker/docker"
      version = "~> 3.0.2"
    }
  }
}

provider "docker" {}

resource "docker_image" "nginx_image" {
  name         = "nginx:latest"
  keep_locally = false
}

resource "docker_container" "nginx_container" {
  name  = "terraform-nginx"
  image = docker_image.nginx_image.name

  ports {
    internal = 80
    external = 8080
  }
} ==> docker1.tf 

terraform init, plan, apply, destroy


terraform {
  required_providers {
    docker = {
      source  = "kreuzwerker/docker"
      version = "~> 3.0.2"
    }
  }
}

provider "docker" {}

resource "docker_image" "nginx_image" {
  name         = "nginx:latest"
  keep_locally = true
}

resource "docker_container" "nginx_container" {
  name  = "terraform-nginx-custom"
  image = docker_image.nginx_image.name

  ports {
    internal = 80
    external = 8082
  }

  volumes {
    host_path      = <path to html>
    container_path = "/usr/share/nginx/html/index.html"
  }
} ==> docker2.tf

terraform init, plan, apply, destroy
------------------------------------------------------------------------------------------------------------
EXP8

StartSonar server ==> localhost:9000
username, passwd = admin
create new project
locally and token name
type of project
other and os = windows
copy command 
open cmd paste command

#----- Default SonarQube server
#sonar.host.url=http://localhost:9000
#----- Default source code encoding
#sonar.sourceEncoding=UTF-8
sonar.projectKey=<project name>
sonar.projectName=<project name>
sonar.projectVersion=1.0
#sonar.projectBaseDir= <project source>
sonar.sources=<file source> ===> C:/SonarScanner/conf/Sonar-scanner.properties

any well formed code for pass 

def R(m):  # poor function name, no docstring
 a=50     # unused variable
 if(m>=40):print("pass") # bad formatting
 else:
  print("fail")

R(float(input("Marks: "))) # no validation, poor style  ======> for fail
-------------------------------------------------------------------------------------------------------------
EXP9

Lambda function create, execution role under aws policy template
add event, test event, go to logs in cloudwatch


10 To create Lambda function using Python to display “Hello_StudentName&quot;.  

python

def lambda_handler(event, context):
    student_name = "Sumeet Prajapati"  # replace with your name
    return {
        'statusCode': 200,
        'body': f"Hello_{student_name}"
    }

node
export const handler = async (event, context) => {
    const studentName = "Sumeet Prajapati";
    return {
        statusCode: 200,
        body: `Hello_${studentName}`
    };
};

-------------------------------------------------------------------------------------------------------------
EXP10

Create execution role using IAM, AmazonS3FullAccess,AWSLambdaFullAccess,CloudWatchFullAcess
create s3 bucket, create lambda function
create new test event for lambda function

import json
import boto3
s3 = boto3.client('s3')  # Create an S3 client
def lambda_handler(event, context):
    bucket = 'prajyotibucket1234'  # Define your S3 bucket name
    dataToUpload = {}  # Initialize an empty dictionary
    # Add key-value pairs to the dictionary
    dataToUpload['PID'] = '231083'
    dataToUpload['DEPT'] = 'INFT'
    dataToUpload['NAME'] = 'SMEET'
    dataToUpload['FILE'] = 'BLUEMETH'
    # Define the filename, adding the .json extension
    fileName = 'BLUEMETH' + '.json'
    # Convert the dataToUpload dictionary to a JSON byte stream
    uploadByteStream = bytes(json.dumps(dataToUpload).encode('UTF-8'))
    # Upload the JSON byte stream to S3
    s3.put_object(Bucket=bucket, Key=fileName, Body=uploadByteStream)
    print(f"Object has been uploaded to {bucket} with key {fileName}") ======> lambda_function.py 

invoke function, check json in bucket
---------------------------------------------------------------------------------------------------------------










